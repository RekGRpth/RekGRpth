Меня зовут Георгий и тема моего доклада:

Прикладная логика внутри базы данных. Шаблонизация. Рендеринг. Рассылка.

Как вообще мне пришла в голову такая идея - поместить прикладную логику внутрь базы данных? В то время как очень многим не нравится помещать в базу данных даже бизнес логику!
Я много лет проработал с биллингом и поэтому под бизнес логикой внутри базы данных понимаю всякие вычисления, ограничения, внешние ключи, триггеры и т.д.,
а под прикладной логикой всякие действия: шаблонизировать документ, отрендерить его в pdf, отослать pdf по электронной почте, послать смс о необходимости пополнить баланс, включить/выключить телефон на телефонной станции или интернет на циске/микротике и т.д.
Конечно, все эти действия можно делать и вне базы данных, и так все обычно и делают. Но тогда возникает потребность в инфраструктуре для всего этого, как всё это запускать, параллелить, мониторить и т.д.
А у меня как раз есть планировщий асинхронных заданий pg_task, в котором всё это уже реализовано, т.е. автоматичсекий запуск, распараллеливание, в качестве мониторинга всё пишется обратно в таблицу в базе данных, даже транзакционность присутствует!
К тому же, если уже есть база данных и планировщик, то дополнительно не надо никакой инфраструктуры городить и управлять только базой данных гораздо проще.
Вот так у меня и возникла идея поместить не только бизнес логику, но и прикладну логику тоже внутрь базы данных.
Для этого пришлось написать несколько плагинов для постгреса. Большинство из них простые и действуют по принципу: вызывается функция из расширения, в которую в качестве аргументов что-то передаётся и она возвращает результат.
На время работы этой функции запрос как бы подвисает, потому что база постргрес не асинхронная. Поэтому также нет никакого смысла использовать так реализованную прикладную логику внутри базы из внешних клиентов к базе.
Гораздо проще реализовать эту логику на клиенте базы. Именно для этого, чтобы бессмысленно не использовать клиентов базы, как раз и исползуется планировщих асинхронных заданий.
Так работает шаблонизация и рендеринг.

Итак,

Шаблонизация.

Когда я начинал, мне попался шаблонизатор ctpp2, написанный на C++ и с реализацией в виде плагина к nginx, с интересной особенностью - для использования его шаблоны необходимо было компилировать.
Компилятор представлял консольную программу, которая переводила текстовый файл шаблона в бинарный. Мне не очень хотелось вызывать внешнюю программу внутри базы данных, хотя это и возможно делать с помощью расширения plsh.
Поэтому я стал искать другой шаблонизатор с реализацией на C и нашёл mustache, у которого есть реализации почти на всех языках! Также, нашёл handlebars - надмножество mustache, с реализацией на C и многих других языках.
Оба эти шаблонизатора я прикрутил в виде плагинов в постгрес и nginx, а также в питон для сравнения произаодительности с нативными питоновыми реализациями (сишная версия mustache оказалась на порядок быстрее питоновой).
Как уже говорилось выше, интерфейс для шаблонизации очень простой. Вызывается функция, в которую в качестве аргументов передаётся документ в виде json, и шаблон в виде текста, функция шаблонизирует и возвращает результат в виде текста.
Например, следующий запрос
SELECT mustach('{"a":"b"}', '{{a}}');
вернёт
b
Интерфейс у handlebars абсолютно идентичный.
Из интересных особенностей реализации mustach могу отметить, что результат выполнения передаётся через файл в оперативной памяти, который предварительно создаётся функцией open_memstream.
Шаблонизация сама по себе в биллинге мало чем полезна, поэтому мне понадобился ещё и

Рендеринг.

Здесь под рендерингом я понимаю преобразование HTML-файла в PDF-файл. Для этого я нашёл несколько библиотек и все их прикрутил в виде плагинов в постгрес и nginx, а также парочку в питон.
Итак, первым я нашёл wkhtmltopdf - довольно тяжёлая библиотка, написанная на C++ с биндингом в C. Мало того, что она занимает много места, так ещё и активно использует треды и не очень охотно их освобождает/завершает, что особенно плохо при работе в nginx.
Поэтому я стал искать далше и нашёл wthtmltopdf, точнее, прямо такой библиотеки нет, но я её выдрал из фреймворка wt WebToolKit, в котором был рендеринг на C++, а я только дописал биндинг в C по аналогии с wkhtmltopdf.
Но тоже мне она не очень понравилась, потому, что требует либы для плюсов. И я нашёл чисто сишную библиотеку mupdf. Из недостатков мне показалось, что она занимала тоже слишком много места для докер образа.
Наконец, я нашёл консольную утилиту htmldoc, написанную на C с элементами на C++, но что мне больше всего понравилось, так это её конечный размер всего в несколько мегабайт! К сожалению, она не была готова в виде разделяемой библиотеки, поэтому мне пришлось это доделывать самому.
Несколько правок в мейкфайле и у меня появилась разделяемая библиотека наряду с консольной утилитой.
Постгресовый интрефейс я к ней сделал тоже очень простой. Несколько функций, которые добавляют файл, или текст или урл в контекст, и ещё пара функций для преобразования в PDF или PS всего, что было добавлено в контекст. В результате преобразования, очевидно, получается не текст, а бинарь.
Здесь также, не только результат выполнения передаётся через файл в оперативной памяти open_memstream, но также и сам HTML-текст в одном случае передаётся через похожий файл в оперативной памяти, но уже с помощью другой родственной функции fmemopen.
При освобождении постргресового мемори контекста очищается и котекст расширения.
Рендеринг PDF-ок, конечно хорошо, но для их передачи клиентам необходима

Рассылка.

Казалось бы причём тут рассылка электронно почты и курл?! А вот, оказывается, курл умеет не только в HTTP-запросы, но также и FTP, SMTP и ещё кучу других полезных протоколов!
Изначально мне попался плагин к постгресу pgsql-http, я его очень подробно изучил и мне он очень понравился за исключением того, что он использует лишь малую часть библиотеки libcurl, а также мне показалась слишком сложной реализация формата запроса.
Ещё я нашёл pg_net с теми же недостатками и поэтому запилил свою версию - pg_curl, в которой по максимуму реализоал почти все возможности курла, а именно, сделал интерфейс почти ко всем функциям, которые принимают строковые или числовые аргументы.
И теперь я могу прямо из базы делать не только HTTP-запросы, но и отсылать электронну почту или копировать файлы по FTP или SCP! Все функции pg_curl можно разделить на несколько типов. Есть простые функции, которые устанавливают всевозможные опции курла.
Также, есть простые функуии, которые добавляют заголовки, а также файлы, аттачи и т.п. Ещё есть простые функции, которые получают различные результаты запросов. И, наконец, есть довольно сложная функция, которая запускает собственно выполнение запроса в курле.
До недавнего времени, я использовал лишь curl_easy_perform, что позволяло одновременно выполнять только один запрос. Но этим летом я значительно усовершентсвовал расширение, добавив поддержку curl_multi_perform, что позволило делать несколько запросов одновременно.
Причём поменял сигнатуры всех функций настолько мягко, что если бы кто-то использовал старую версию pg_curl, а потом скомпилировал новую, то у него бы ничего не сломалось и без обновления расширения командой ALTER EXTENSION UPDATE!
Из интересного можно отметить, что курл позволяет задать кастомное управление памятью, чем я и воспользовался передав туда управление через постгресовые мемори контексты.
Алексей заметил, что при этом курл использует мультитредовый резолвинг, что иногда приводило к сегфолтам, поэтому я во все врапперы над постгрессовыми мемори контекстами, передаваемими курлу, добавил мьютексы, чтобы убедиться, что никакой тред параллельно не вызовет соответствующие функции.
Также я добавил огромное число ifdef-ов для поддержки всевозможных версий курла. Если какая-то функция ещё не поддерживается текущей старой версией курла, или наоборот, в текущей новой версии курла удалили какую-то неподдерживаемую функцию, то выдётся соответсвующее сообщение об ошибке.
Ну и по-традиции, я пока поддерживаю все версии постгресса, начиная с 9.4 и включая 17, на которых расширение собирается и немного тестируется.
